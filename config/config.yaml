# Configuration file for Chat-HPT-1

# Model configuration
model:
  vocab_size: 256
  d_model: 64
  n_heads: 2
  n_layers: 2
  max_seq_length: 512

# Training configuration
training:
  batch_size: 4
  num_epochs: 3
  learning_rate: 0.001
  max_grad_norm: 1.0
  weight_decay: 0.01

# Inference configuration
inference:
  max_new_tokens: 50
  temperature: 0.7
  top_p: 0.9
  top_k: 40

# Data paths
paths:
  train_data: "data/text/training_data.txt"
  # eval_data: "data/text/eval_data.txt"
  model_dir: "data/models/"
  output_dir: "output/inference_outputs/"

# MLflow configuration
mlflow:
  tracking_uri: "./mlruns"
  experiment_name: "chat-hpt-1"
  register_model: true
